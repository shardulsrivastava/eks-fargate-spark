#!/usr/bin/env bash

set -euo pipefail

cd "$(dirname "$0")/.."

function green() {
    text="${1:- }"
    echo -e "\033[32m${text}\033[0m"
}

function install_dep() {
    green "Installing eksctl"
    curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
    sudo mv /tmp/eksctl /usr/local/bin

    green "Installing kubectl"
    curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
}

green "Installing pre-requisites"
install_dep

green "Deploying Cluster => spark-cluster"
eksctl create cluster -f spark-cluster.yaml

green "Cluster => "
kubectl config current-context

green "Setting up Spark on K8s Operator"
helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
helm upgrade \
    --install \
    spark-operator \
    spark-operator/spark-operator \
    --namespace spark \
    --create-namespace \
    --set webhook.enable=true \
    --set sparkJobNamespace=spark \
    --set serviceAccounts.spark.name=spark \
    --set logLevel=10 \
    --version 1.1.6 \
    --wait

while [[ $(kubectl -n spark get pods -l app.kubernetes.io/name=spark-operator -o 'jsonpath={..status.conditions[?(@.type=="Ready")].status}') != "True" ]]; do 
    echo "waiting for opertor pod to be ready" && sleep 1; 
done

green "Submitting Spark PI application to the cluster"
kubectl apply -f manifests/spark-pi.yaml
